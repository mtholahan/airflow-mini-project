# Airflow Mini Projects

This project demonstrates a simple Airflow DAG that downloads stock data and calculates the average closing price.

## üóÇÔ∏è Project Structure
- `dags/`: our 2 mini-project DAGs
- `screenshots/`: GUI evidence of successful DAG execution
- `scripts/`: our non-DAG scripts
- `marketvol_dag.py`: Defines the DAG and tasks
- **`log_analyzer_dag.py`**: Error accumulator/counter for **`marketvol_dag.py`** runs
- **`docker-compose.yaml`**: Defines the full Airflow stack (webserver, scheduler, worker, etc.) with PostgreSQL and Redis, using local folders for live DAG development.
- `requirements.txt`: Dependencies to run Airflow and the DAG
- `start-airflow.sh`: Helper script to launch the environment
- 

## üìà DAG Overview
The `marketvol` DAG:
- Accepts a `date` parameter
- Downloads AAPL and TSLA stock data for that date
- Saves CSVs locally to `~/airflow/data/{date}/`
- Computes and logs average closing prices

## ‚úÖ Sample Output
From task logs (`compute_avg_close`):

Average Close prices:
 ticker
 AAPL    230.889999
 TSLA    335.160004

```
## üñ•Ô∏è Screenshots
- [DAG List View](./screenshots/dags_view.png)
- [Task Log Output](./screenshots/task_logs_compute_avg_close.png)

```



The`log_analyzer_dag.py`DAG:

- Analyzes task-level log files generated by the `marketvol` DAG.  
- This DAG executes daily, after the main pipeline completes. It parses logs located in  `~/airflow/logs/marketvol/`, counts event types (e.g. INFO, ERROR), and stores the results  for diagnostic or audit purposes. Useful for monitoring task behavior and surfacing anomalies.
